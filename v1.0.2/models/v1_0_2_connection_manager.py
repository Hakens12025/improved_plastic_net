"""
ä¼˜åŒ–ç‰ˆè¿æ¥ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨ v1.0.2 - æ€§èƒ½ä¼˜åŒ–çš„è¿æ¥ç®¡ç†

æ ¸å¿ƒä¼˜åŒ–ï¼š
1. å‘é‡åŒ–å…±åŒæ¿€æ´»è®¡ç®—ï¼Œæ›¿ä»£é€å¯¹å¾ªç¯
2. å†…å­˜ä¼˜åŒ–ï¼šä½¿ç”¨æ›´ç´§å‡‘çš„æ•°æ®ç±»å‹
3. EMAå¹³æ»‘ï¼šæ›¿ä»£å†å²çª—å£å­˜å‚¨
4. æ‰¹é‡æ“ä½œï¼šå‡å°‘GPU-CPUåŒæ­¥
"""

import torch
import heapq
from typing import List, Tuple, Set
import numpy as np


class OptimizedConnectionManager:
    """ä¼˜åŒ–ç‰ˆè¿æ¥ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨"""

    def __init__(self, num_neurons: int, protection_period: int = 75, device: str = 'cpu'):
        """
        åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆè¿æ¥ç®¡ç†å™¨

        Args:
            num_neurons: ç¥ç»å…ƒæ•°é‡
            protection_period: æ–°è¿æ¥çš„ä¿æŠ¤æœŸï¼ˆæ­¥æ•°ï¼‰
            device: è®¾å¤‡ï¼ˆ'cpu' æˆ– 'cuda'ï¼‰
        """
        self.num_neurons = num_neurons
        self.protection_period = protection_period
        self.device = device

        # ğŸš€ æ€§èƒ½ä¼˜åŒ–1ï¼šä½¿ç”¨æ›´ç´§å‡‘çš„æ•°æ®ç±»å‹
        self.connection_age = torch.zeros(num_neurons, num_neurons, dtype=torch.int16, device=device)
        
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–2ï¼šå…±åŒæ¿€æ´»ä½¿ç”¨EMAï¼Œæ— éœ€å†å²çª—å£
        self.coactivation_ema = torch.zeros(num_neurons, num_neurons, dtype=torch.float16, device=device)
        self.coactivation_decay = 0.95  # EMAè¡°å‡å› å­
        
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–3ï¼šé¢„åˆ†é…å€™é€‰æ± ï¼ˆå›ºå®šå¤§å°ï¼‰
        self.max_candidates = 50  # å‡å°‘å€™é€‰æ± å¤§å°
        self.candidate_priorities = torch.zeros(self.max_candidates, 3, device=device)  # [priority, source, target]
        self.candidate_count = 0

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_steps = 0

    def update_connection_ages_vectorized(self, adj_mask: torch.Tensor):
        """
        ğŸš€ å‘é‡åŒ–æ›´æ–°æ‰€æœ‰æ´»è·ƒè¿æ¥çš„å¹´é¾„

        Args:
            adj_mask: é‚»æ¥çŸ©é˜µæ©ç 
        """
        with torch.no_grad():
            # å‘é‡åŒ–æ“ä½œï¼šä¸€æ¬¡æ€§æ›´æ–°æ‰€æœ‰æ´»è·ƒè¿æ¥çš„å¹´é¾„
            active_mask = adj_mask > 0
            self.connection_age[active_mask] = torch.clamp(
                self.connection_age[active_mask] + 1, 
                max=32767  # int16æœ€å¤§å€¼
            )

    def reset_connection_age(self, source: int, target: int):
        """
        é‡ç½®è¿æ¥å¹´é¾„ï¼ˆç”¨äºæ–°å»ºè¿æ¥ï¼‰

        Args:
            source: æºç¥ç»å…ƒ
            target: ç›®æ ‡ç¥ç»å…ƒ
        """
        self.connection_age[source, target] = 0

    def get_connection_status(self, source: int, target: int) -> str:
        """
        è·å–è¿æ¥çŠ¶æ€

        Args:
            source: æºç¥ç»å…ƒ
            target: ç›®æ ‡ç¥ç»å…ƒ

        Returns:
            'protected' æˆ– 'mature'
        """
        age = self.connection_age[source, target].item()
        if age < self.protection_period:
            return 'protected'
        else:
            return 'mature'

    def can_be_pruned_vectorized(self, adj_mask: torch.Tensor, credit_scores: torch.Tensor, prune_threshold: float) -> torch.Tensor:
        """
        ğŸš€ å‘é‡åŒ–åˆ¤æ–­å“ªäº›è¿æ¥å¯ä»¥è¢«å‰ªæï¼ˆæ”¹è¿›ç‰ˆï¼šæ¸è¿›å¼ä¿æŠ¤æœŸï¼‰

        Args:
            adj_mask: é‚»æ¥çŸ©é˜µæ©ç 
            credit_scores: ä¿¡ç”¨åˆ†æ•°çŸ©é˜µ
            prune_threshold: å‰ªæé˜ˆå€¼

        Returns:
            å¯ä»¥å‰ªæçš„è¿æ¥æ©ç 
        """
        with torch.no_grad():
            # å‘é‡åŒ–æ¡ä»¶æ£€æŸ¥
            active_mask = adj_mask > 0

            # ğŸ”¥ æ”¹è¿›1ï¼šæ¸è¿›å¼ä¿æŠ¤æœŸï¼ˆè€Œéç¡¬é˜ˆå€¼ï¼‰
            # ä¿æŠ¤æœŸå†…çš„è¿æ¥ä¹Ÿå¯èƒ½è¢«å‰ªæï¼Œä½†æ¦‚ç‡éšå¹´é¾„å¢åŠ è€Œå¢åŠ 
            age_ratio = self.connection_age.float() / max(self.protection_period, 1)
            age_ratio = torch.clamp(age_ratio, 0.0, 1.0)  # é™åˆ¶åœ¨ [0, 1]

            # ğŸ”¥ æ”¹è¿›2ï¼šåŠ¨æ€å‰ªæé˜ˆå€¼ï¼ˆå¹´é¾„è¶Šå°ï¼Œé˜ˆå€¼è¶Šä¸¥æ ¼ï¼‰
            # å¹´é¾„=0: é˜ˆå€¼ = prune_threshold * 0.1ï¼ˆå¾ˆéš¾å‰ªæï¼‰
            # å¹´é¾„=protection_period: é˜ˆå€¼ = prune_threshold * 1.0ï¼ˆæ­£å¸¸å‰ªæï¼‰
            # å¹´é¾„>protection_period: é˜ˆå€¼ = prune_threshold * 1.5ï¼ˆæ›´å®¹æ˜“å‰ªæï¼‰
            dynamic_threshold = prune_threshold * (0.1 + 0.9 * age_ratio + 0.5 * (age_ratio > 1.0).float())

            # ä¿¡ç”¨åˆ†æ•°ä½äºåŠ¨æ€é˜ˆå€¼çš„è¿æ¥å¯ä»¥è¢«å‰ªæ
            credit_mask = credit_scores < dynamic_threshold

            # ç»¼åˆæ¡ä»¶ï¼šæ´»è·ƒ + ä½ä¿¡ç”¨åˆ†æ•°ï¼ˆåŠ¨æ€é˜ˆå€¼ï¼‰
            can_prune_mask = active_mask & credit_mask

            return can_prune_mask

    def can_be_pruned(self, source: int, target: int, credit_score: float, prune_threshold: float) -> bool:
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼šåˆ¤æ–­å•ä¸ªè¿æ¥æ˜¯å¦å¯ä»¥è¢«å‰ªæ

        Args:
            source: æºç¥ç»å…ƒ
            target: ç›®æ ‡ç¥ç»å…ƒ
            credit_score: è¿æ¥çš„ä¿¡ç”¨åˆ†æ•°
            prune_threshold: å‰ªæé˜ˆå€¼

        Returns:
            Trueè¡¨ç¤ºå¯ä»¥å‰ªæï¼ŒFalseè¡¨ç¤ºä¸å¯ä»¥
        """
        # æ£€æŸ¥ä¿æŠ¤æœŸ
        if self.connection_age[source, target].item() < self.protection_period:
            return False

        # æ£€æŸ¥ä¿¡ç”¨åˆ†æ•°
        if credit_score < prune_threshold:
            return True

        return False

    def update_coactivation_vectorized(self, activations: torch.Tensor):
        """
        ğŸš€ å‘é‡åŒ–æ›´æ–°å…±åŒæ¿€æ´»è®¡æ•°

        Args:
            activations: ç¥ç»å…ƒæ¿€æ´»å€¼ (batch_size, num_neurons)
        """
        with torch.no_grad():
            # ğŸš€ ä¼˜åŒ–1ï¼šä½¿ç”¨äºŒå€¼åŒ–æ¿€æ´»ï¼ˆå‘é‡åŒ–ï¼‰
            binary_act = (activations > 0).half()  # ä½¿ç”¨åŠç²¾åº¦ä»¥èŠ‚çœå†…å­˜
            
            # ğŸš€ ä¼˜åŒ–2ï¼šå‘é‡åŒ–è®¡ç®—å…±åŒæ¿€æ´»çŸ©é˜µ
            # coactivation_batch[i,j] = åŒæ—¶æ¿€æ´»çš„æ‰¹æ¬¡æ¯”ä¾‹
            batch_size = activations.size(0)
            coactivation_batch = torch.matmul(binary_act.t(), binary_act) / batch_size
            
            # ğŸš€ ä¼˜åŒ–3ï¼šEMAæ›´æ–°ï¼ˆæ— éœ€å­˜å‚¨å†å²ï¼‰
            self.coactivation_ema = (
                self.coactivation_decay * self.coactivation_ema
                + (1.0 - self.coactivation_decay) * coactivation_batch.half()
            )

            self.total_steps += 1

    def update_coactivation(self, activations: torch.Tensor):
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼šæ›´æ–°å…±åŒæ¿€æ´»è®¡æ•°
        """
        self.update_coactivation_vectorized(activations)

    def calculate_connection_priority_vectorized(self, sources: torch.Tensor, targets: torch.Tensor, 
                                               relative_distances: torch.Tensor) -> torch.Tensor:
        """
        ğŸš€ å‘é‡åŒ–æ‰¹é‡è®¡ç®—è¿æ¥ä¼˜å…ˆçº§åˆ†æ•°

        Args:
            sources: æºç¥ç»å…ƒå¼ é‡
            targets: ç›®æ ‡ç¥ç»å…ƒå¼ é‡
            relative_distances: ç›¸å¯¹è·ç¦»å¼ é‡

        Returns:
            ä¼˜å…ˆçº§åˆ†æ•°å¼ é‡
        """
        with torch.no_grad():
            # ğŸš€ å‘é‡åŒ–è·ç¦»å› å­è®¡ç®—
            valid_dist_mask = (relative_distances >= 2) & (relative_distances <= 3)
            distance_factors = torch.where(
                valid_dist_mask,
                1.0 / relative_distances,
                torch.zeros_like(relative_distances)
            )
            
            # ğŸš€ å‘é‡åŒ–å…±åŒæ¿€æ´»å› å­è·å–
            coactivation_factors = self.coactivation_ema[sources, targets].float()
            
            # ğŸš€ å‘é‡åŒ–ç»¼åˆè¯„åˆ†
            priorities = distance_factors * coactivation_factors
            
            return priorities

    def calculate_connection_priority(self, source: int, target: int, relative_distance: float) -> float:
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼šè®¡ç®—å•ä¸ªè¿æ¥ä¼˜å…ˆçº§åˆ†æ•°

        Args:
            source: æºç¥ç»å…ƒ
            target: ç›®æ ‡ç¥ç»å…ƒ
            relative_distance: ç›¸å¯¹æ‹“æ‰‘è·ç¦»

        Returns:
            ä¼˜å…ˆçº§åˆ†æ•°ï¼ˆè¶Šé«˜è¶Šä¼˜å…ˆï¼‰
        """
        # ç›¸å¯¹è·ç¦»å› å­ï¼ˆè·ç¦»è¶Šè¿‘ï¼Œä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        if relative_distance == float('inf') or relative_distance < 2 or relative_distance > 3:
            return 0.0

        distance_factor = 1.0 / relative_distance

        # ğŸš€ ä½¿ç”¨EMAå€¼æ›¿ä»£å†å²è®¡æ•°
        coactivation_factor = self.coactivation_ema[source, target].item()

        # ç»¼åˆè¯„åˆ†
        priority = distance_factor * coactivation_factor

        return priority

    def add_candidate_vectorized(self, sources: torch.Tensor, targets: torch.Tensor, priorities: torch.Tensor):
        """
        ğŸš€ å‘é‡åŒ–æ‰¹é‡æ·»åŠ è¿æ¥å€™é€‰

        Args:
            sources: æºç¥ç»å…ƒå¼ é‡
            targets: ç›®æ ‡ç¥ç»å…ƒå¼ é‡
            priorities: ä¼˜å…ˆçº§å¼ é‡
        """
        if len(sources) == 0:
            return
            
        with torch.no_grad():
            # ğŸš€ ç­›é€‰æœ‰æ•ˆå€™é€‰
            valid_mask = priorities > 0
            if not valid_mask.any():
                return
                
            valid_sources = sources[valid_mask]
            valid_targets = targets[valid_mask]
            valid_priorities = priorities[valid_mask]
            
            # ğŸš€ æŒ‰ä¼˜å…ˆçº§æ’åºå¹¶å–top-k
            _, top_indices = torch.topk(valid_priorities, 
                                       min(len(valid_priorities), self.max_candidates - self.candidate_count))
            
            # ğŸš€ æ‰¹é‡æ·»åŠ åˆ°å€™é€‰æ± 
            for i, idx in enumerate(top_indices):
                if self.candidate_count < self.max_candidates:
                    self.candidate_priorities[self.candidate_count] = torch.tensor([
                        valid_priorities[idx].item(),
                        valid_sources[idx].item(), 
                        valid_targets[idx].item()
                    ], device=self.device)
                    self.candidate_count += 1

    def add_candidate(self, source: int, target: int, priority: float):
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼šæ·»åŠ å•ä¸ªè¿æ¥å€™é€‰åˆ°ä¼˜å…ˆé˜Ÿåˆ—
        """
        # ç®€åŒ–å®ç°ï¼šç›´æ¥æ·»åŠ åˆ°å¼ é‡
        if self.candidate_count < self.max_candidates and priority > 0:
            self.candidate_priorities[self.candidate_count] = torch.tensor([
                priority, source, target
            ], device=self.device)
            self.candidate_count += 1

    def get_top_candidates_vectorized(self, n: int = 10) -> List[Tuple[int, int, float]]:
        """
        ğŸš€ å‘é‡åŒ–è·å–ä¼˜å…ˆçº§æœ€é«˜çš„nä¸ªå€™é€‰è¿æ¥

        Args:
            n: å€™é€‰æ•°é‡

        Returns:
            [(source, target, priority), ...]
        """
        if self.candidate_count == 0:
            return []

        with torch.no_grad():
            # ğŸš€ å‘é‡åŒ–æ’åºå‰min(n, self.candidate_count)ä¸ªå€™é€‰
            actual_n = min(n, self.candidate_count)
            candidates = self.candidate_priorities[:self.candidate_count]
            
            # æŒ‰ä¼˜å…ˆçº§é™åºæ’åº
            _, sorted_indices = torch.sort(candidates[:, 0], descending=True)
            top_candidates = candidates[sorted_indices[:actual_n]]
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
            result = []
            for i in range(actual_n):
                priority = top_candidates[i, 0].item()
                source = int(top_candidates[i, 1].item())
                target = int(top_candidates[i, 2].item())
                result.append((source, target, priority))
                
            return result

    def get_top_candidates(self, n: int = 10) -> List[Tuple[int, int, float]]:
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼šè·å–ä¼˜å…ˆçº§æœ€é«˜çš„nä¸ªå€™é€‰è¿æ¥
        """
        return self.get_top_candidates_vectorized(n)

    def clear_candidates(self):
        """æ¸…ç©ºå€™é€‰æ± """
        with torch.no_grad():
            self.candidate_priorities.zero_()
            self.candidate_count = 0

    def get_protected_connections_vectorized(self, adj_mask: torch.Tensor) -> torch.Tensor:
        """
        ğŸš€ å‘é‡åŒ–è·å–æ‰€æœ‰å¤„äºä¿æŠ¤æœŸçš„è¿æ¥

        Args:
            adj_mask: é‚»æ¥çŸ©é˜µæ©ç 

        Returns:
            ä¿æŠ¤æœŸè¿æ¥çš„æ©ç 
        """
        with torch.no_grad():
            active_mask = adj_mask > 0
            protected_mask = (self.connection_age < self.protection_period) & active_mask
            return protected_mask

    def get_protected_connections(self, adj_mask: torch.Tensor) -> torch.Tensor:
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼šè·å–æ‰€æœ‰å¤„äºä¿æŠ¤æœŸçš„è¿æ¥
        """
        return self.get_protected_connections_vectorized(adj_mask)

    def get_statistics(self) -> dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        with torch.no_grad():
            return {
                'total_steps': self.total_steps,
                'avg_coactivation': self.coactivation_ema.float().mean().item(),
                'max_coactivation': self.coactivation_ema.float().max().item(),
                'candidate_pool_size': self.candidate_count,
                'memory_usage_mb': (
                    self.connection_age.numel() * self.connection_age.element_size() +
                    self.coactivation_ema.numel() * self.coactivation_ema.element_size()
                ) / (1024 * 1024)
            }

    def to(self, device):
        """
        å°†è¿æ¥ç®¡ç†å™¨çš„å¼ é‡ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡

        Args:
            device: ç›®æ ‡è®¾å¤‡
        """
        self.device = device
        self.connection_age = self.connection_age.to(device)
        self.coactivation_ema = self.coactivation_ema.to(device)
        self.candidate_priorities = self.candidate_priorities.to(device)
        return self