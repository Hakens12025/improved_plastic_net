# 训练配置快速参考

## 当前配置

### 模型参数
- **神经元数量**: 1000（从400提升）
- **训练轮数**: 10（从5提升）
- **批次大小**: 128
- **学习率**: 0.001
- **可塑性更新间隔**: 50个batch

### 预期性能（1000神经元，10轮，GPU）

| 指标 | 预期值 |
|------|--------|
| **总训练时间** | 100-300秒 |
| **平均每轮时间** | 10-30秒 |
| **测试准确率** | ≥ 98% |
| **最终稀疏度** | 60-80% |
| **连接变化率** | 5-10% |
| **GPU内存使用** | 2-4GB |

### 与400神经元对比

| 指标 | 400神经元 | 1000神经元 | 变化 |
|------|-----------|------------|------|
| 神经元数 | 400 | 1000 | **+150%** |
| 训练轮数 | 5 | 10 | **+100%** |
| 最大连接数 | 79,800 | 499,500 | **+526%** |
| 参数量 | ~160K | ~1M | **+525%** |
| 预期训练时间 | 25-100s | 100-300s | **+3-4x** |
| 预期准确率 | ≥98% | ≥98.5% | 略有提升 |

## 运行方式

### 方式1: 使用启动脚本（推荐）

**Windows**:
```cmd
run_experiment.bat
```

**Linux/Mac**:
```bash
bash run_experiment.sh
```

### 方式2: 使用配置文件

```bash
conda activate pt_gpu
python run_with_config.py
```

修改 `config.py` 文件可以调整所有参数。

### 方式3: 直接运行

```bash
conda activate pt_gpu
cd experiments
python v1_0_3_mnist_baseline.py
```

## 参数调整建议

### 如果训练太慢

```python
# 在 config.py 或实验脚本中修改：
NUM_NEURONS = 600              # 减少神经元
PLASTICITY_INTERVAL = 100      # 减少更新频率
EPOCHS = 5                     # 减少训练轮数
```

### 如果想要更高准确率

```python
NUM_NEURONS = 1500             # 增加神经元
ITERATIONS = 7                 # 增加内部迭代
EPOCHS = 15                    # 增加训练轮数
LEARNING_RATE = 0.0005         # 降低学习率
```

### 如果内存不足

```python
NUM_NEURONS = 600              # 减少神经元
BATCH_SIZE = 64                # 减少批次大小
INITIAL_SPARSITY = 0.7         # 增加初始稀疏度
```

### 如果连接变化率异常

**变化率太高（>15%）**:
```python
PROTECTION_PERIOD = 100        # 增加保护期
GROWTH_THRESHOLD = 0.5         # 提高生长阈值
```

**变化率太低（<3%）**:
```python
PROTECTION_PERIOD = 50         # 减少保护期
GROWTH_THRESHOLD = 0.2         # 降低生长阈值
PLASTICITY_INTERVAL = 30       # 增加更新频率
```

## 监控训练过程

### 关键输出指标

1. **每轮训练**
   ```
   Epoch 1/10: Loss: 0.45 | Acc: 85.2% | Connections: 245,678
   ```

2. **可塑性更新**
   ```
   Applying neuroplasticity at batch 50
   Pruned: 1,234 connections, Added: 1,567 connections
   Change rate: 7.8%
   ```

3. **连接年龄统计**
   ```
   连接年龄统计:
     总连接数: 245,678
     平均年龄: 125.5步
     中位数年龄: 98.0步
     最大年龄: 450步
     保护期内连接: 12,345 (5.0%)
   ```

### 正常训练的特征

✅ **连接数动态变化** - 不是单调递减
✅ **连接年龄分布广** - 有新连接也有老连接
✅ **变化率在5-10%** - 持续演化
✅ **准确率稳步提升** - 每轮都有进步
✅ **保护期连接<20%** - 大部分连接已成熟

### 异常情况处理

❌ **所有连接年龄相同** → 可塑性更新太少，减小PLASTICITY_INTERVAL
❌ **连接数单调递减** → 只有剪枝没有生长，检查代码
❌ **变化率>20%** → 太不稳定，增加PROTECTION_PERIOD
❌ **准确率不提升** → 学习率或神经元数量问题

## 输出文件

训练完成后会生成：

1. **v1_0_3_optimized_plastic_net_fashion_mnist.pth**
   - 训练好的模型权重
   - 大小: ~10-20MB（1000神经元）

2. **v1_0_3_optimized_plastic_net_fashion_mnist_performance.json**
   - 性能统计数据
   - 包含训练时间、准确率等

3. **training_history.png**
   - 训练历史曲线
   - 损失、准确率、连接数变化

4. **topology.png**
   - 网络拓扑结构
   - 邻接矩阵和网络图

5. **connection_age.png**
   - 连接年龄分布直方图
   - 显示连接的生命周期

## 性能优化提示

### GPU优化

1. **确保使用GPU**
   ```python
   # 检查CUDA是否可用
   import torch
   print(torch.cuda.is_available())  # 应该是True
   ```

2. **监控GPU使用**
   ```bash
   # 另开一个终端
   nvidia-smi -l 1  # 每秒刷新
   ```

3. **预期GPU利用率**: 70-90%

### 训练速度参考

| 配置 | CPU (i7) | GPU (RTX 3060) | GPU (RTX 4090) |
|------|----------|----------------|----------------|
| 400神经元, 5轮 | 300-600s | 25-100s | 10-30s |
| 1000神经元, 10轮 | 2000-4000s | 100-300s | 40-120s |

## 故障排除

### 问题1: CUDA out of memory

**解决方案**:
```python
NUM_NEURONS = 600      # 减少神经元
BATCH_SIZE = 64        # 减少批次
```

### 问题2: 训练速度很慢

**检查**:
- GPU是否被使用？
- CUDA是否可用？
- 是否有其他程序占用GPU？

### 问题3: 准确率不理想

**尝试**:
- 增加神经元数量
- 增加训练轮数
- 调整学习率
- 检查数据集是否正确加载

### 问题4: 连接年龄异常

**原因**: 可塑性更新太少

**解决**:
```python
PLASTICITY_INTERVAL = 30  # 从50减少到30
```

## 下一步

1. **运行训练**: `run_experiment.bat`
2. **观察输出**: 检查连接年龄分布是否正常
3. **查看可视化**: 打开生成的PNG图片
4. **调整参数**: 根据结果修改 `config.py`
5. **对比实验**: 尝试不同的神经元数量

---

**配置更新时间**: 2026-02-03
**当前配置**: 1000神经元, 10轮训练
**预期训练时间**: 100-300秒（GPU）

